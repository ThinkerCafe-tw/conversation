"""
æ¸¬è©¦é›†é«”è¨˜æ†¶å»£æ’­æ•ˆæœ
"""

import os
import time
from dotenv import load_dotenv
from knowledge_graph import KnowledgeGraph
from collective_memory import CollectiveMemorySystem, MemoryAnalyzer
from frequency_bot_firestore import FrequencyBotFirestore
import google.generativeai as genai

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
if os.path.exists('.env'):
    load_dotenv()

def test_collective_broadcast():
    """æ¸¬è©¦é›†é«”è¨˜æ†¶å»£æ’­ç”Ÿæˆ"""
    print("=== é›†é«”è¨˜æ†¶å»£æ’­æ¸¬è©¦ ===\n")
    
    # åˆå§‹åŒ–ç³»çµ±
    print("1. åˆå§‹åŒ–ç³»çµ±...")
    try:
        graph = KnowledgeGraph()
        memory_system = CollectiveMemorySystem(graph)
        frequency_bot = FrequencyBotFirestore(graph)
        print("   âœ… ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ åˆå§‹åŒ–å¤±æ•—: {e}")
        return
    
    # æ¨¡æ“¬ç”¨æˆ¶è¨Šæ¯
    print("\n2. æ¨¡æ“¬ç”¨æˆ¶è¨Šæ¯...")
    test_messages = [
        ("ç”¨æˆ¶0001", "ä»Šå¤©å¤©æ°£çœŸå¥½ï¼Œå¿ƒæƒ…ä¹Ÿè·Ÿè‘—å¥½èµ·ä¾†äº†"),
        ("ç”¨æˆ¶0002", "å¥½ç´¯å•Šï¼Œæƒ³è¦æ”¾é¬†ä¸€ä¸‹"),
        ("ç”¨æˆ¶0003", "æœ‰äººè¦ä¸€èµ·ç©æ¥é¾å—ï¼Ÿ"),
        ("ç”¨æˆ¶0001", "æˆ‘ä¹Ÿæƒ³ç©ï¼é–‹å§‹å§"),
        ("ç”¨æˆ¶0004", "æ™šå®‰å¤§å®¶ï¼Œæº–å‚™ç¡è¦ºäº†"),
        ("ç”¨æˆ¶0002", "çœŸçš„å¥½ç´¯ï¼Œæ˜å¤©é‚„è¦æ—©èµ·"),
        ("ç”¨æˆ¶0005", "ä»Šæ™šçš„æœˆäº®å¾ˆç¾å‘¢"),
        ("ç”¨æˆ¶0003", "æ¥é¾ï¼šæœˆäº®"),
        ("ç”¨æˆ¶0001", "äº®æ™¶æ™¶"),
        ("ç”¨æˆ¶0006", "å¤§å®¶éƒ½åœ¨èŠä»€éº¼å‘€"),
        ("ç”¨æˆ¶0007", "å‰›ä¸‹ç­ï¼ŒéŒ¯éä»€éº¼äº†å—"),
        ("ç”¨æˆ¶0008", "æƒ³åƒå®µå¤œï¼Œæœ‰æ¨è–¦å—"),
        ("ç”¨æˆ¶0002", "æˆ‘ä¹Ÿé¤“äº†ï¼Œä¸€èµ·é»å¤–é€ï¼Ÿ"),
        ("ç”¨æˆ¶0009", "ä»Šå¤©éå¾—çœŸå¿«"),
        ("ç”¨æˆ¶0010", "æ™‚é–“ç¸½æ˜¯ä¸å¤ ç”¨")
    ]
    
    # å°‡è¨Šæ¯åŠ å…¥å»£æ’­æ± å’Œé›†é«”è¨˜æ†¶
    for user_id, message in test_messages:
        frequency_bot.add_to_broadcast(message, user_id)
        print(f"   å·²åŠ å…¥: [{user_id}] {message[:20]}...")
    
    print(f"\n   âœ… å·²åŠ å…¥ {len(test_messages)} å‰‡è¨Šæ¯")
    
    # ç”Ÿæˆé›†é«”è¨˜æ†¶å»£æ’­æç¤ºè©
    print("\n3. ç”Ÿæˆé›†é«”è¨˜æ†¶å»£æ’­æç¤ºè©...")
    current_hour = int(time.time() // 3600)
    prompt = memory_system.generate_broadcast_prompt(current_hour)
    
    print(f"   æç¤ºè©é•·åº¦: {len(prompt)} å­—")
    print(f"   æç¤ºè©é è¦½:")
    print("   " + "-" * 50)
    print(prompt[:500] + "...")
    print("   " + "-" * 50)
    
    # ä½¿ç”¨ AI ç”Ÿæˆå»£æ’­
    print("\n4. ä½¿ç”¨ Gemini AI ç”Ÿæˆå»£æ’­...")
    try:
        genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        response = model.generate_content(prompt)
        if response and response.candidates:
            broadcast = response.candidates[0].content.parts[0].text
            
            print("\nğŸŒ™ ç”Ÿæˆçš„é›†é«”è¨˜æ†¶å»£æ’­ï¼š")
            print("=" * 60)
            print(broadcast)
            print("=" * 60)
            
            # åˆ†æå»£æ’­æ•ˆæœ
            print("\n5. å»£æ’­æ•ˆæœåˆ†æï¼š")
            analyze_broadcast_effect(broadcast, test_messages)
            
        else:
            print("   âŒ AI ç”Ÿæˆå¤±æ•—")
            
    except Exception as e:
        print(f"   âŒ ç”Ÿæˆå»£æ’­æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # ç”¨æˆ¶æ¼”åŒ–åˆ†æ
    print("\n6. ç”¨æˆ¶æ¼”åŒ–åˆ†æ...")
    analyzer = MemoryAnalyzer(graph)
    
    for user_id in ["ç”¨æˆ¶0001", "ç”¨æˆ¶0002", "ç”¨æˆ¶0003"]:
        evolution = analyzer.analyze_user_evolution(user_id)
        print(f"\n   {user_id}:")
        print(f"   - è¨Šæ¯æ•¸é‡: {evolution.get('message_count', 0)}")
        print(f"   - æƒ…ç·’æ­·ç¨‹: {' â†’ '.join(evolution.get('emotion_journey', []))}")
        if evolution.get('topic_expansion', {}).get('current_interests'):
            print(f"   - é—œæ³¨è©±é¡Œ: {', '.join(evolution['topic_expansion']['current_interests'])}")
    
    # æ‰¾å‡ºå…±æŒ¯æ¨¡å¼
    print("\n7. ç¤¾ç¾¤å…±æŒ¯æ¨¡å¼...")
    patterns = analyzer.find_resonance_patterns()
    print(f"   æ´»èºé«˜å³°: {patterns.get('peak_hours', [])}")
    print(f"   ç†±é–€è©±é¡Œ: {patterns.get('viral_topics', [])}")
    
    graph.close()
    print("\n=== æ¸¬è©¦å®Œæˆ ===")

def analyze_broadcast_effect(broadcast: str, original_messages):
    """åˆ†æå»£æ’­æ˜¯å¦æˆåŠŸå›æ‡‰äº†ç”¨æˆ¶"""
    responded_users = []
    
    # æª¢æŸ¥é—œéµè©åŒ¹é…
    keywords_map = {
        "ç´¯": ["ç”¨æˆ¶0002", "ç”¨æˆ¶0006"],
        "æ¥é¾": ["ç”¨æˆ¶0003", "ç”¨æˆ¶0001"],
        "æœˆäº®": ["ç”¨æˆ¶0005", "ç”¨æˆ¶0003"],
        "é¤“": ["ç”¨æˆ¶0008", "ç”¨æˆ¶0002"],
        "æ™‚é–“": ["ç”¨æˆ¶0009", "ç”¨æˆ¶0010"]
    }
    
    for keyword, users in keywords_map.items():
        if keyword in broadcast:
            responded_users.extend(users)
    
    unique_responded = set(responded_users)
    total_users = len(set([msg[0] for msg in original_messages]))
    
    print(f"   - å›æ‡‰è¦†è“‹ç‡: {len(unique_responded)}/{total_users} ç”¨æˆ¶ ({len(unique_responded)/total_users*100:.1f}%)")
    print(f"   - è¢«å›æ‡‰çš„ç”¨æˆ¶: {', '.join(unique_responded)}")
    
    # æª¢æŸ¥é›†é«”åŒ–ç”¨èª
    collective_words = ["æˆ‘å€‘", "å¤§å®¶", "ä¸€èµ·", "å…±åŒ", "å½¼æ­¤"]
    collective_count = sum(1 for word in collective_words if word in broadcast)
    print(f"   - é›†é«”åŒ–ç”¨èª: {collective_count} å€‹")
    
    # æª¢æŸ¥æ™‚é–“æ„ŸçŸ¥
    time_words = ["ä»Šæ™š", "å¤œæ™š", "æ­¤åˆ»", "é€™å€‹æ™‚å€™"]
    has_time_awareness = any(word in broadcast for word in time_words)
    print(f"   - æ™‚é–“æ„ŸçŸ¥: {'âœ… æœ‰' if has_time_awareness else 'âŒ ç„¡'}")

if __name__ == "__main__":
    test_collective_broadcast()